{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 02: Deep FF Networks (Predicting Winners in DOTA 2)\n",
    "\n",
    "The assignment consists of fitting DL model to predict which of two teams will win a DOTA2 game.This is a\n",
    "simple binary classification problem: aka output -1 if team1 wins and output +1 if team2 wins (no draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Dota2 Games Results\n",
    "train_data = pd.read_csv('dota2_results\\dota2Train.csv', header = None)\n",
    "test_data = pd.read_csv('dota2_results\\dota2Test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating header for the datasets\n",
    "tn_col_list = ['x'+ str(col) for col in range(len(train_data.columns))]\n",
    "ts_col_list = ['x'+ str(col) for col in range(len(test_data.columns))]\n",
    "\n",
    "# Add header to datasets\n",
    "train_data.columns = tn_col_list\n",
    "test_data.columns = ts_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing Target columns from feature columns\n",
    "X_train = train_data.iloc[:,1:]\n",
    "y_train = train_data.iloc[:,0]\n",
    "\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92650, 116)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We shuffle the train data row-wise to remove any possible stratification imposed on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle train data\n",
    "y_shfl_train, X_shfl_train = shuffle(y_train, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We'll use scikit-learn's MinMaxScaler class to scale x_shfl_train data down to be on a scale from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_scl_train = scaler.fit_transform(X_shfl_train)\n",
    "X_scl_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Given that we can't calculate cross entropy loss with labels -1 and 1. we convert target values to 0 and 1. Using the LabelEncoder class from scikit-learn, the fit_transform () function is applied on the output variable to create a new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "y_encd_train = encoder.fit_transform(y_shfl_train)\n",
    "y_encd_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Reshaping the output variables into 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the target variables\n",
    "y_rshp_train = y_encd_train.reshape(-1,1)\n",
    "y_rshp_test = y_encd_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting and Evaluating Deep Feed Forward Neural Network Model\n",
    "The model is developed using the following steps\n",
    "1. Define the structure of model. Specifying an input_shape of 116 for the input layer becuase our dataset has 116  input variables.\n",
    "\n",
    "2. Compile the model with binary_crossentropy cost function, adam optimizer, and performance metric (accuracy).\n",
    "\n",
    "3. Fit the compiled model on the train dataset. Additionally, a validation set of 30% of the train data is held back for validation, using the validation_split parameter.\n",
    "\n",
    "4. Evaluate the model using the test data. we will run for a small number of iterations of 50 epochs and use a relatively small batch size of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the structure of the DFF Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(116,), activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6636 - accuracy: 0.5982 - val_loss: 0.6697 - val_accuracy: 0.5799\n",
      "Epoch 2/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6626 - accuracy: 0.6001 - val_loss: 0.6652 - val_accuracy: 0.5924\n",
      "Epoch 3/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6620 - accuracy: 0.6004 - val_loss: 0.6674 - val_accuracy: 0.5867\n",
      "Epoch 4/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6626 - accuracy: 0.5999 - val_loss: 0.6724 - val_accuracy: 0.5856\n",
      "Epoch 5/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6622 - accuracy: 0.6005 - val_loss: 0.6646 - val_accuracy: 0.5972\n",
      "Epoch 6/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6616 - accuracy: 0.6012 - val_loss: 0.6661 - val_accuracy: 0.5880\n",
      "Epoch 7/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6622 - accuracy: 0.6014 - val_loss: 0.6662 - val_accuracy: 0.5877\n",
      "Epoch 8/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6620 - accuracy: 0.6009 - val_loss: 0.6667 - val_accuracy: 0.5858\n",
      "Epoch 9/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6619 - accuracy: 0.6004 - val_loss: 0.6689 - val_accuracy: 0.5845\n",
      "Epoch 10/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6614 - accuracy: 0.6015 - val_loss: 0.6650 - val_accuracy: 0.5896\n",
      "Epoch 11/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6612 - accuracy: 0.6016 - val_loss: 0.6659 - val_accuracy: 0.5920\n",
      "Epoch 12/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6615 - accuracy: 0.6025 - val_loss: 0.6640 - val_accuracy: 0.5951\n",
      "Epoch 13/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6612 - accuracy: 0.6031 - val_loss: 0.6661 - val_accuracy: 0.5921\n",
      "Epoch 14/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6614 - accuracy: 0.6025 - val_loss: 0.6639 - val_accuracy: 0.5914\n",
      "Epoch 15/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6610 - accuracy: 0.6030 - val_loss: 0.6652 - val_accuracy: 0.5941\n",
      "Epoch 16/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6611 - accuracy: 0.6019 - val_loss: 0.6642 - val_accuracy: 0.5937\n",
      "Epoch 17/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6611 - accuracy: 0.6033 - val_loss: 0.6674 - val_accuracy: 0.5922\n",
      "Epoch 18/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6611 - accuracy: 0.6025 - val_loss: 0.6650 - val_accuracy: 0.5935\n",
      "Epoch 19/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6609 - accuracy: 0.6044 - val_loss: 0.6663 - val_accuracy: 0.5900\n",
      "Epoch 20/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6610 - accuracy: 0.6033 - val_loss: 0.6671 - val_accuracy: 0.5906\n",
      "Epoch 21/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6610 - accuracy: 0.6041 - val_loss: 0.6649 - val_accuracy: 0.5920\n",
      "Epoch 22/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6611 - accuracy: 0.6025 - val_loss: 0.6736 - val_accuracy: 0.5760\n",
      "Epoch 23/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6609 - accuracy: 0.6038 - val_loss: 0.6653 - val_accuracy: 0.5979\n",
      "Epoch 24/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6606 - accuracy: 0.6038 - val_loss: 0.6648 - val_accuracy: 0.5921\n",
      "Epoch 25/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6608 - accuracy: 0.6035 - val_loss: 0.6655 - val_accuracy: 0.5913\n",
      "Epoch 26/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6608 - accuracy: 0.6030 - val_loss: 0.6719 - val_accuracy: 0.5835\n",
      "Epoch 27/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6608 - accuracy: 0.6023 - val_loss: 0.6668 - val_accuracy: 0.5919\n",
      "Epoch 28/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6608 - accuracy: 0.6032 - val_loss: 0.6665 - val_accuracy: 0.5906\n",
      "Epoch 29/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6606 - accuracy: 0.6036 - val_loss: 0.6791 - val_accuracy: 0.5737\n",
      "Epoch 30/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6605 - accuracy: 0.6041 - val_loss: 0.6676 - val_accuracy: 0.5893\n",
      "Epoch 31/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6606 - accuracy: 0.6043 - val_loss: 0.6745 - val_accuracy: 0.5775\n",
      "Epoch 32/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6606 - accuracy: 0.6036 - val_loss: 0.6653 - val_accuracy: 0.5917\n",
      "Epoch 33/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6606 - accuracy: 0.6025 - val_loss: 0.6645 - val_accuracy: 0.5930\n",
      "Epoch 34/50\n",
      "834/834 [==============================] - 2s 3ms/step - loss: 0.6606 - accuracy: 0.6045 - val_loss: 0.6652 - val_accuracy: 0.5919\n",
      "Epoch 35/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6605 - accuracy: 0.6044 - val_loss: 0.6667 - val_accuracy: 0.5955\n",
      "Epoch 36/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6602 - accuracy: 0.6037 - val_loss: 0.6682 - val_accuracy: 0.5862\n",
      "Epoch 37/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6605 - accuracy: 0.6045 - val_loss: 0.6651 - val_accuracy: 0.5953\n",
      "Epoch 38/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6604 - accuracy: 0.6044 - val_loss: 0.6658 - val_accuracy: 0.5938\n",
      "Epoch 39/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6605 - accuracy: 0.6042 - val_loss: 0.6667 - val_accuracy: 0.5866\n",
      "Epoch 40/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6605 - accuracy: 0.6032 - val_loss: 0.6687 - val_accuracy: 0.5933\n",
      "Epoch 41/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6607 - accuracy: 0.6038 - val_loss: 0.6656 - val_accuracy: 0.5924\n",
      "Epoch 42/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6605 - accuracy: 0.6032 - val_loss: 0.6656 - val_accuracy: 0.5937\n",
      "Epoch 43/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6606 - accuracy: 0.6032 - val_loss: 0.6645 - val_accuracy: 0.5941\n",
      "Epoch 44/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6604 - accuracy: 0.6030 - val_loss: 0.6700 - val_accuracy: 0.5910\n",
      "Epoch 45/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6605 - accuracy: 0.6029 - val_loss: 0.6672 - val_accuracy: 0.5899\n",
      "Epoch 46/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6607 - accuracy: 0.6044 - val_loss: 0.6742 - val_accuracy: 0.5807\n",
      "Epoch 47/50\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 0.6604 - accuracy: 0.6042 - val_loss: 0.6649 - val_accuracy: 0.5938\n",
      "Epoch 48/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6604 - accuracy: 0.6044 - val_loss: 0.6645 - val_accuracy: 0.5933\n",
      "Epoch 49/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6604 - accuracy: 0.6038 - val_loss: 0.6645 - val_accuracy: 0.5954\n",
      "Epoch 50/50\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 0.6602 - accuracy: 0.6037 - val_loss: 0.6683 - val_accuracy: 0.5889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15d81c77790>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_scl_train, y_rshp_train, validation_split=0.10, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each iteration, the output of the loss function shows higher value. This means that the model is performing very poorly. A low value for the loss would mean our model is performing very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 958us/step - loss: 0.6638 - accuracy: 0.5941\n",
      "Accuracy in the testing data: 0.5941324830055237\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_scl_test, y_rshp_test)\n",
    "print('Accuracy in the testing data:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing accuracy is 0.5941, while my training is 0.6037. Indeed, the model isn't performing so well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting and Evaluating RandomForest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of the Random Forest model, using Scikit-Learn’s RandomizedSearchCV, which will randomly search parameters within a range of hyperparameters defined. We then fit this to our training data. We pass both the features and the target variable, so the model can learn. RandomizedSearchCV will train many models till it gets the best model fitting the train data. This function also uses cross validation, which means it splits the data into five equal-sized groups and uses 4 to train and 1 to test the result. It will loop through each group and give an accuracy score, which is averaged to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C3DC60640&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C3DE168B0&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C3DC60640&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C3DE168B0&gt;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C3DC60640>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000027C3DE168B0>})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rand_search.fit(X_scl_train, y_rshp_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 19, 'n_estimators': 318}\n"
     ]
    }
   ],
   "source": [
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with the best model\n",
    "y_pred = best_rf.predict(X_scl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5820866524188848\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_rshp_test.ravel(), y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting and Evaluating Logistic Regression classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a Logistic Regression classifier object using the LogisticRegression() function with random_state for reproducibility. Then, fit your model on the train set using fit() and perform prediction on the test set using predict(). Accuracy is computed by comparing actual test set values and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=16)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_scl_train, y_rshp_train.ravel())\n",
    "\n",
    "y_pred = logreg.predict(X_scl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5980182630658636\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",accuracy_score(y_rshp_test.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the accuracy of the DFF neural network model with that of other ML models like the Random Forest Classifier and Logistic Regression Classifier, all of them performed relatively the same. \n",
    "\n",
    "Accuracy of DFF neural Network = 59.41% \n",
    "\n",
    "Accuracy of DFF neural Network = 58.20%\n",
    "\n",
    "Accuracy of DFF neural Network = 59.80%\n",
    "\n",
    "A possible reason could be because the dataset is not variate enough. They are lot of similar values in your dataset. That might be a reason of the low accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
