{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â A bit more advanced example\n",
    "\n",
    "Binary classification.\n",
    "\n",
    "Keras also includes an [IMDB](https://www.imdb.com) (Internet Movie Database) dataset. \n",
    "\n",
    "This dataset contains 50k movie reviews from the users of the website. All the reviews are either very positive, or very negative.\n",
    "\n",
    "The 50k reviews are split into 25k for training, and 25k for testing, and in each one of those data splits, 50% of the reviews are positive and 50% are negative. Therefore, the classes are perfectly balanced.\n",
    "\n",
    "The reviews have already been pre-processed, and for memory efficiency, the words have been converted to integers. So the bare reviews you will see in the training data come as integers and therefore are unreadable as they come. But since each integer represents a work in the English dictionary, we can easily reconstruct the original reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import layers, models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAgain, if this last line of code doesn't work, run this:\\n\\nimport ssl\\nssl._create_default_https_context = ssl._create_unverified_context\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The num_words parameter in this load_data function is to take the top 10000 most common words in all of the reviews.\n",
    "Uncommon words will not be loaded.\n",
    "'''\n",
    "NUM_MOST_COMMON_WORDS = 10000\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = imdb.load_data(num_words=NUM_MOST_COMMON_WORDS)\n",
    "\n",
    "'''\n",
    "Again, if this last line of code doesn't work, run this:\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a function to reconstruct a message, so we can explore the training data:\n",
    "invert_dictionary = imdb.get_word_index() # Word to integer dictionary given by the dataset\n",
    "dictionary = {value: key for key, value in invert_dictionary.items()}\n",
    "\n",
    "\n",
    "def reconstruct_message(sample):\n",
    "    review = ' '.join(dictionary[i-3] for i in sample if i-3 in dictionary)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst mistake of my life br br i picked this movie up at target for 5 because i figured hey it's sandler i can get some cheap laughs i was wrong completely wrong mid way through the film all three of my friends were asleep and i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon bashing my head in i stuck that damn movie in the and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "i'm probably one of the biggest nancy drew fans out there i've read every book three times over and i've played a lot of the nancy drew games i loved this movie it kept you entertained the whole time you watched it i went with about 10 of my friends and everyone loved it there were three woman sitting behind us who appeared to be in their late 30's to early 40's and i asked them how they liked it they said they loved it so you see it will be an entertainment to all ages you just have to give it a chance and it teaches a lesson too just be yourself even if everyone around you is exactly alike so overall this move was great i'm going to see it a second time now so stop bashing it please its a really good movie\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "mike gordon is witness to the brutal murder of his mother and suicide of his father jon twenty years later mike a group of his friends to his family's cabin in the woods for a halloween party while playing a game where the guests confess and confront their worst fears mike tries to the spirit of his late father it is soon discovered that spirit a wooden indian in the cabin the statue comes to life and the blood bath begins br br most of the f x are not very convincing and the movie takes on a cheap teen slasher theme stale story acted cast members of note are kelly benson phillip rhys byron chief moon and veteran actress\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "this movie is not as good as all the movies of christ i've ever seen and i'm quite amazed that in this story wants to finish jesus when the as well the other movies state differently it lacks also a very important issue the none of the other movies skip this very important part the faith of all of us christians lies in this very event as paul says in one of his letters if christ did not rise from the dead our faith is vain a very impressive scene for me in this movie was seeing on the streets the remains of the that were used when jesus entered br br finally and in opposition to my jewish co jesus was not a myth and as a matter of fact he was also a jew there are plenty of documents and that prove the existence of this extraordinary man or should i said god become a man that indeed changed mankind i strongly advise him given he is a to read about the most brilliant jewish of the 1st century\n",
      "------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feel free to add/remove indices here to check different reviews:\n",
    "REVIEWS_TO_CHECK = [4, 64, 9876, 15543]\n",
    "\n",
    "for r in REVIEWS_TO_CHECK:\n",
    "    print(reconstruct_message(train_X[r]))\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot feed a list of integers (or a list of words) directly into a neural network. We have to vectorise these lists (covert them into **tensors** - more on tensors shortly). \n",
    "\n",
    "We are going to use a simple transformation to vectorise them:\n",
    "1. Create a list of 10000 integers, filled with 0s\n",
    "2. If the word with index 40 (remember the words are integers) is in the review, then the 40th position in the previous list is set to 1\n",
    "\n",
    "We will do those two steps with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise_reviews(reviews_data, input_features=NUM_MOST_COMMON_WORDS):\n",
    "    result = np.zeros((len(reviews_data), input_features))\n",
    "    for review, word in enumerate(reviews_data):\n",
    "        result[review, word] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_train_X = vectorise_reviews(train_X)\n",
    "vect_test_X = vectorise_reviews(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a Deep Feedforward Neural Net like we saw in the slides\n",
    "model = models.Sequential() \n",
    "\n",
    "'''\n",
    "We now add layers. As we mentioned in the previous interactive activity We do not need to add \n",
    "the input layer in Keras. However, I am now explicitly adding it so we don't have to declare the input_shape\n",
    "parameter in the first hidden layer.\n",
    "\n",
    "This time we are adding 2 hidden layers and then the output layer.\n",
    "NOTE: I am putting 16 hidden neurons, but feel free to change it.\n",
    "(check the slides to make sense of these lines of code)\n",
    "'''\n",
    "\n",
    "model.add(layers.Input(shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "# We have 2 classes, so 1 sigmoid neuron that outputs the probability of being one class or another is enough\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that Keras includes different versions of the negative log likelihood (cross-entropy) function...\n",
    "# depending on the output type of our ANN \n",
    "# (in the previous interactive activity was categorical/multi-class, now is binary)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# As we will see in the future, we could define our own loss functions and performance metrics and pass them to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set:\n",
    "\n",
    "This time we will do it slightly different. We will build a validation set to do a first check on our fitted model.\n",
    "\n",
    "For build this, we will set apart the first 10k samples from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = vect_train_X[:10000]\n",
    "remaining_train_X = vect_train_X[10000:]\n",
    "\n",
    "val_y = train_y[:10000]\n",
    "remaining_train_y = train_y[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can directly use that validation dataset during our optimisation process, to check how we expect the model to behave with the test data later on!\n",
    "\n",
    "Keras implements this very neatly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.5396 - accuracy: 0.7790 - val_loss: 0.4339 - val_accuracy: 0.8410\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3250 - accuracy: 0.8996 - val_loss: 0.3270 - val_accuracy: 0.8732\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.2385 - accuracy: 0.9229 - val_loss: 0.2887 - val_accuracy: 0.8873\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.1850 - accuracy: 0.9413 - val_loss: 0.2770 - val_accuracy: 0.8924\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1520 - accuracy: 0.9509 - val_loss: 0.2785 - val_accuracy: 0.8883\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1249 - accuracy: 0.9602 - val_loss: 0.2901 - val_accuracy: 0.8860\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.1037 - accuracy: 0.9678 - val_loss: 0.3057 - val_accuracy: 0.8857\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0863 - accuracy: 0.9742 - val_loss: 0.3269 - val_accuracy: 0.8816\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0705 - accuracy: 0.9802 - val_loss: 0.3558 - val_accuracy: 0.8812\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0580 - accuracy: 0.9843 - val_loss: 0.3803 - val_accuracy: 0.8740\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0498 - accuracy: 0.9889 - val_loss: 0.4047 - val_accuracy: 0.8787\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0376 - accuracy: 0.9921 - val_loss: 0.4411 - val_accuracy: 0.8675\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0309 - accuracy: 0.9941 - val_loss: 0.5285 - val_accuracy: 0.8665\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0251 - accuracy: 0.9953 - val_loss: 0.5024 - val_accuracy: 0.8745\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.5279 - val_accuracy: 0.8701\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0156 - accuracy: 0.9974 - val_loss: 0.5711 - val_accuracy: 0.8711\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0129 - accuracy: 0.9984 - val_loss: 0.6016 - val_accuracy: 0.8704\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.6297 - val_accuracy: 0.8675\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.6676 - val_accuracy: 0.8662\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.7059 - val_accuracy: 0.8657\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    remaining_train_X,\n",
    "    remaining_train_y,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(val_X, val_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that between each epoch there is a small delay. This is because Keras is calculating the predictions for the validation dataset.\n",
    "\n",
    "And also for each epoch we are not getting the `val_loss` and `val_accuracy` parameters, which mean exactly what you are thinking: the loss and accuracies obtained after predicting for the validation test using that epoch's ANN configuration.\n",
    "\n",
    "As you can clearly see, the fact that our training accuracy is becoming higher (and the training loss lower) doesn't mean that our validation accuracies and/or loss are also improving! This is because our model is likely to be overfitting.\n",
    "\n",
    "Let's plot them from the `history` we got when fitting our ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have these parameters stored in our fitting history:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print('We have these parameters stored in our fitting history:')\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing some data for the plot:\n",
    "accuracies = history_dict['accuracy']\n",
    "val_accuracies = history_dict['val_accuracy']\n",
    "epochs = range(1, len(accuracies)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, accuracies, 'ro', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracies, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracies over the optimisation Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above we can see that our Validation Accuracy peaked between the 3rd and the 5th epoch. After that, our ANN became more and more overfitted to the training data, without making any progress on other data.\n",
    "\n",
    "Let's re-fit our model but with just 4 epochs and see if the test accuracy we get is similar to the validation one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.5041 - accuracy: 0.7903 - val_loss: 0.3944 - val_accuracy: 0.8487\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2947 - accuracy: 0.9025 - val_loss: 0.3133 - val_accuracy: 0.8749\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2166 - accuracy: 0.9285 - val_loss: 0.2969 - val_accuracy: 0.8802\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1707 - accuracy: 0.9445 - val_loss: 0.2748 - val_accuracy: 0.8901\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Input(shape=(10000,)))\n",
    "model2.add(layers.Dense(16, activation='relu'))\n",
    "model2.add(layers.Dense(16, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history2 = model2.fit(\n",
    "    remaining_train_X,\n",
    "    remaining_train_y,\n",
    "    epochs=4, # The best Epoch we found before it became overfitted!\n",
    "    batch_size=512,\n",
    "    validation_data=(val_X, val_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2942 - accuracy: 0.8828\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model2.evaluate(vect_test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9444666504859924\n",
      "Validation accuracy: 0.8901000022888184\n",
      "Test accuracy: 0.8828399777412415\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy:', history2.history['accuracy'][-1])\n",
    "print('Validation accuracy:', history2.history['val_accuracy'][-1])\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test accuracy should now very similar to the validation accuracy we were getting when training our model, and the overfitting effect should be smaller.\n",
    "\n",
    "Please take a moment to reflect on the results too: The fact that with a few lines of code we can achieve real accuracies of between 85% and 90% to distinguish positive and negative comments is impressive. And we have just used  two hidden layers of 16 neurons each.\n",
    "\n",
    "This is where the hype comes in the community, and hopefully produces some excitement for you too. \n",
    "\n",
    "**As always, play with the code:** Add layers, add neurons to the layers, change the parameters I specified, etc. You cannot break anything.\n",
    "\n",
    "**There is a strong possibility** that you will find much better ANN architectures. \n",
    "\n",
    "### Here are some ideas for you to practice:\n",
    "* We used two hidden layers; try using one or three hidden layers, and see how doing so affects validation and test accuracies\n",
    "* Try using hidden layers with more or less neurons. We used 16. Try 8, 32, 64. What happens with the accuracies?\n",
    "* Try using the Mean Square Error (`mse`) instead of `binary_crossentropy` as a loss function\n",
    "* Try using the `tanh` activation in your hidden layers, instead of `relu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
