{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ensemble in Sklearn\n",
    "\n",
    "This week we are going to review how basic ensembles can be created in Sklearn. \n",
    "\n",
    "We will focus on the Voting classifiers and the Bagging classifiers: \n",
    "\n",
    "* Voting Classifier\n",
    "* Bagging\n",
    "\n",
    "To exemplify these classifiers, let me tell you a story: On the island of [Hoarafushi](https://www.google.com/maps/place/Hoarafushi/@6.97941,72.874541,8691m/data=!3m1!1e3!4m5!3m4!1s0x3b6d0fd6b9e86b61:0xa214d5fa9f65c83a!8m2!3d6.9826462!4d72.8951151), in the Maldives, there is a tower with a LiDAR sensor on top. This radar is taking mesurements every ten minutes on different weather conditions: wind direction and intensity at different heights, air pressure, relative humidity, the sensor's temperature... And finally there is one column called: `r1_rain_percentage_occurance`.\n",
    "\n",
    "Can we predict whether `r1_rain_percentage_occurance` is different than zero? (i.e. if it rained in that 10 minutes between one reading and the previous one?\n",
    "\n",
    "### Be patient...\n",
    "**Note:** The data will take a little bit to download (around 3-5mins depending on your internet connection), it is a bit large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://energydata.info/dataset/d2fbd01c-31f5-4180-9796-ad5828c9d742/resource/51e19759-28d4-4fc8-8558-b33ad7805a22/download/wind-measurements_maldives_hoarafushi_wb-esmap-qc.csv'\n",
    "\n",
    "data_stream=requests.get(data_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(io.StringIO(data_stream.decode('utf-8')), sep=',', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will delete a few columns to simplify the data a little bit (this is NOT feature selection, I am just randomly dropping)\n",
    "columns_to_delete = [\n",
    "    'time', 'a20_wind_speed_mean', 'a20_wind_speed_stddev', 'a20_wind_speed_min', 'a20_wind_speed_max', 'd20_wind_direction_mean',\n",
    "    'a20_vertical_wind_speed_mean', 'a20_turbulence_intensity', 'a30_wind_speed_mean', 'a30_wind_speed_stddev',\n",
    "    'a30_wind_speed_min', 'a30_wind_speed_max', 'd30_wind_direction_mean', 'a30_vertical_wind_speed_mean',\n",
    "    'a30_turbulence_intensity', 'a39_wind_speed_mean', 'a39_wind_speed_stddev', 'a39_wind_speed_min', 'a39_wind_speed_max',\n",
    "    'd39_wind_direction_mean', 'a39_vertical_wind_speed_mean', 'a39_turbulence_intensity', 'a60_wind_speed_mean',\n",
    "    'a60_wind_speed_stddev', 'a60_wind_speed_min', 'a60_wind_speed_max', 'd60_wind_direction_mean', 'a60_vertical_wind_speed_mean',\n",
    "    'a60_turbulence_intensity', 'a80_wind_speed_mean', 'a80_wind_speed_stddev', 'a80_wind_speed_min', 'a80_wind_speed_max',\n",
    "    'd80_wind_direction_mean', 'a80_vertical_wind_speed_mean', 'a80_turbulence_intensity', 'a100_wind_speed_mean',\n",
    "    'a100_wind_speed_stddev', 'a100_wind_speed_min', 'a100_wind_speed_max', 'd100_wind_direction_mean',\n",
    "    'a100_vertical_wind_speed_mean', 'a100_turbulence_intensity', 'a120_wind_speed_mean', 'a120_wind_speed_stddev',\n",
    "    'a120_wind_speed_min', 'a120_wind_speed_max', 'd120_wind_direction_mean', 'a120_vertical_wind_speed_mean',\n",
    "    'a120_turbulence_intensity', 'a150_wind_speed_mean', 'a150_wind_speed_stddev', 'a150_wind_speed_min', 'a150_wind_speed_max',\n",
    "    'd150_wind_direction_mean', 'a150_vertical_wind_speed_mean', 'a150_turbulence_intensity', 'a11_points_in_average',\n",
    "    'a20_points_in_average', 'a30_points_in_average', 'a39_points_in_average', 'a50_points_in_average', 'a60_points_in_average',\n",
    "    'a80_points_in_average', 'a100_points_in_average', 'a120_points_in_average', 'a150_points_in_average', 'a200_points_in_average',\n",
    "    'v1_voltage_external_mean', 'v1_voltage_internal_mean', 'b1_bearing_device_mean', 'b1_tilt_device_mean',\n",
    "]\n",
    "\n",
    "df.drop(columns_to_delete, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59 samples in which the target is null. We will delete those\n"
     ]
    }
   ],
   "source": [
    "print('There are',len(df[df['r1_rain_percentage_occurance']==9999]),'samples in which the target is null. We will delete those')\n",
    "df = df[df.r1_rain_percentage_occurance != 9999]\n",
    "\n",
    "# Now we will categorise the target: 0 if didn't rain, 1 if it rained, even a little.\n",
    "df.rename(columns = {'r1_rain_percentage_occurance':'target'}, inplace = True)\n",
    "df['target'] = df['target'].apply(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "# Let's encode the target variable\n",
    "categoriser = LabelEncoder()\n",
    "categoriser.fit(df['target'])\n",
    "df['target'] = categoriser.transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It did not rain in 96929 samples; and it rained in 6896\n"
     ]
    }
   ],
   "source": [
    "# The dataset is quite imbalanced. Didn't rain much...\n",
    "print('It did not rain in',len(df[df.target == 0]), 'samples; and it rained in', len(df[df.target == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will randomly subsample 7,000 samples of the no-rain class. This is to make our classifiers faster and \n",
    "# also to reduce a little bit the class imbalances. (Sorry, we downloaded so much data for nothing..., although you can\n",
    "# now play with it by sampling more, or just taking all of the dataset)\n",
    "training = df[df['target'] == 0].sample(n=7000)\n",
    "training = training.append(df[df['target']==1])\n",
    "training = training.sample(frac=1) # Sampling everything is actually \"shuffling\" the rows in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By the way, in the data the value 9999 means NULL!\n",
    "training.replace(to_replace=9999, value=np.NaN, inplace=True)\n",
    "\n",
    "X = training.iloc[:, :-1]\n",
    "y = training['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After subsampling, our training data now has 13896 samples\n"
     ]
    }
   ],
   "source": [
    "print('After subsampling, our training data now has', len(training),'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data:\n",
    "mm = MinMaxScaler()\n",
    "X = mm.fit_transform(X)\n",
    "\n",
    "# We will impute the missing data with the median strategy: The missing value will be the median of the column\n",
    "imputer = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the classifiers separately\n",
    "\n",
    "We are going to build an ensemble of 4 classifiers: 2 KNN classifiers (with different neighbours) and 2 SVC classifiers (one with a polynomial kernel and another one with a RBF kernel). \n",
    "\n",
    "But first, let's check their individual Cross-Validation performances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbours = [3, 15]\n",
    "kernels = ['poly', 'rbf']\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for k in k_neighbours:\n",
    "    classifiers.append(KNeighborsClassifier(n_neighbors=k))\n",
    "    \n",
    "# In the SVMs, we set probability=True in order to be able to use predict_proba for soft voting\n",
    "for kernel in kernels:\n",
    "    classifiers.append(SVC(kernel=kernel, probability=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing,  KNeighborsClassifier(n_neighbors=3)\n",
      "KNeighborsClassifier(n_neighbors=3) done\n",
      "Doing,  KNeighborsClassifier(n_neighbors=15)\n",
      "KNeighborsClassifier(n_neighbors=15) done\n",
      "Doing,  SVC(kernel='poly', probability=True)\n",
      "SVC(kernel='poly', probability=True) done\n",
      "Doing,  SVC(probability=True)\n",
      "SVC(probability=True) done\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for c in classifiers:\n",
    "    print('Doing, ', c)\n",
    "    score = cross_validate(\n",
    "        c, X, y, cv=5, scoring='accuracy'\n",
    "    )\n",
    "    print(c, 'done')\n",
    "    scores.append(score['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8074253975732691,\n",
       " 0.8123909796236418,\n",
       " 0.8226099135085597,\n",
       " 0.8196596260235426]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy scores of all of our classifiers are definitely **better than random (over 50%)** and circle around 77-82% for all of them. Let's put them together in a [Voting Ensemble](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html) and see how they perform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingEnsemble = VotingClassifier(\n",
    "    # We can set any list of classifiers (with a string to identify them) as the estimators for our Voting Ensemble!\n",
    "    estimators=[(str(c), c) for c in classifiers],\n",
    "    voting='hard', # Could also be 'soft' if all your classifiers have the predict_proba method\n",
    "    weights=scores, # I will weight the classifiers according to the accuracy score the obtained in the CV training I did just before\n",
    "    n_jobs=-1, # Ensembles are great to work in parallel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing,  VotingClassifier(estimators=[('KNeighborsClassifier(n_neighbors=3)',\n",
      "                              KNeighborsClassifier(n_neighbors=3)),\n",
      "                             ('KNeighborsClassifier(n_neighbors=15)',\n",
      "                              KNeighborsClassifier(n_neighbors=15)),\n",
      "                             (\"SVC(kernel='poly', probability=True)\",\n",
      "                              SVC(kernel='poly', probability=True)),\n",
      "                             ('SVC(probability=True)', SVC(probability=True))],\n",
      "                 n_jobs=-1,\n",
      "                 weights=[0.8074253975732691, 0.8123909796236418,\n",
      "                          0.8226099135085597, 0.8196596260235426])\n",
      "VotingClassifier(estimators=[('KNeighborsClassifier(n_neighbors=3)',\n",
      "                              KNeighborsClassifier(n_neighbors=3)),\n",
      "                             ('KNeighborsClassifier(n_neighbors=15)',\n",
      "                              KNeighborsClassifier(n_neighbors=15)),\n",
      "                             (\"SVC(kernel='poly', probability=True)\",\n",
      "                              SVC(kernel='poly', probability=True)),\n",
      "                             ('SVC(probability=True)', SVC(probability=True))],\n",
      "                 n_jobs=-1,\n",
      "                 weights=[0.8074253975732691, 0.8123909796236418,\n",
      "                          0.8226099135085597, 0.8196596260235426]) done\n"
     ]
    }
   ],
   "source": [
    "print('Doing, ', votingEnsemble)\n",
    "score = cross_validate(\n",
    "    votingEnsemble, X, y, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(votingEnsemble, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score provided by the ensemble: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8227539796158755"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Score provided by the ensemble: ')\n",
    "score['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a *slightly higher accuracy* in the majority voting ensemble. However did you notice that training time? \n",
    "\n",
    "Was the accuracy increase worth the time we had to wait? It will always depend on the problem we are facing, but we need to be careful with this.\n",
    "\n",
    "## Bagging\n",
    "\n",
    "Let's now implement some [**Bagging**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier) strategies in our ensemble: This time we will use an homogeneous ensemble with LogisticRegression, which is faster to train by the way. But first let's see how one single LogisticRegression performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One LogisticRegression score: 0.809585094788509\n"
     ]
    }
   ],
   "source": [
    "score = cross_validate(\n",
    "        LogisticRegression(penalty='l2', max_iter=300, verbose=0), X, y, cv=5, scoring='accuracy'\n",
    "    )\n",
    "print('One LogisticRegression score:', score['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = BaggingClassifier(\n",
    "    base_estimator=LogisticRegression(penalty='l2', max_iter=300, verbose=0),\n",
    "    n_estimators=50, # We will use 50 LogisticRegressions, FEEL FREE TO CHANGE THIS\n",
    "    max_samples=0.30, # A maximum of 30% of the data will be used in each LogisticRegression, FEEL FREE TO CHANGE THIS\n",
    "    n_jobs=-1,\n",
    "    verbose=0, # Put '1' or '2' here if you want to see how Bagging is training each step\n",
    "    \n",
    "    # PLAYGROUND\n",
    "    bootstrap=True,\n",
    "    bootstrap_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing,  BaggingClassifier(base_estimator=LogisticRegression(max_iter=300),\n",
      "                  max_samples=0.3, n_estimators=50, n_jobs=-1)\n",
      "BaggingClassifier(base_estimator=LogisticRegression(max_iter=300),\n",
      "                  max_samples=0.3, n_estimators=50, n_jobs=-1) done\n"
     ]
    }
   ],
   "source": [
    "print('Doing, ', bagging)\n",
    "score = cross_validate(\n",
    "    bagging, X, y, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(bagging, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score provided by the ensemble: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80519546651272"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Score provided by the ensemble: ')\n",
    "score['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's disappointing... The score is actually the same or even worse! What have we done wrong? Can you test some other classifier apart from LogisticRegression and see what happens?\n",
    "\n",
    "**Note:** Not even with 500 Logistic Regressions I was able to improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "baggingDT = BaggingClassifier(\n",
    "    base_estimator=None, # When this is NULL, Bagging will use DecisionTrees as the base estimator\n",
    "    n_estimators=50, # We will use 50 DecisionTreeClassifiers, FEEL FREE TO CHANGE THIS\n",
    "    max_samples=0.30, # A maximum of 30% of the data will be used in each DecisionTree, FEEL FREE TO CHANGE THIS\n",
    "    n_jobs=-1,\n",
    "    verbose=0, # Put '1' or '2' here if you want to see how Bagging is training each step\n",
    "    \n",
    "    # PLAYGROUND\n",
    "    bootstrap=True,\n",
    "    bootstrap_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing,  BaggingClassifier(max_samples=0.3, n_estimators=50, n_jobs=-1)\n",
      "BaggingClassifier(max_samples=0.3, n_estimators=50, n_jobs=-1) done\n"
     ]
    }
   ],
   "source": [
    "print('Doing, ', baggingDT)\n",
    "score = cross_validate(\n",
    "    baggingDT, X, y, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(baggingDT, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score provided by the Decision Tree Bagging ensemble: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8460705289672544"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Score provided by the Decision Tree Bagging ensemble: ')\n",
    "score['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's some improvement at least! (Almost 5% in my case!)\n",
    "\n",
    "At least, after all of the small painful processes and the disappointing results, we can finish this interactive activity, which doesn't even have any plot in it, with a happy ending.\n",
    "\n",
    "# Conclusion and Learning Exercises:\n",
    "\n",
    "I must confess I did this Interactive Activity slightly annoying on purpose: Ensemble is not always good, and I wanted to show that. Just because you use more computing power and do more calculations doesn't mean that you will get better results. We need to be clever about this.\n",
    "\n",
    "This is why this week's Learning Exercises are focused on improving what we have here: \n",
    "* Bagging without DecisionTrees, are there any better weak learners than those? What if we build a Bagging ensemble of Random Forests? (_a Random Jungle?_) - also without Bagging, in the Voting Classifier, this could be an interesting exercise for you.\n",
    "* Majority Voting: Is there any improvement with Soft Voting, compared to Hard Voting?\n",
    "* Can we build an heterogeneous ensemble that improves the individual accuracies by over 5%?\n",
    "* What can happen if we build ensembles of Naive Bayes learners?\n",
    "* Do you remember which one was the fastest classification algorithm to train of the ones you know so far? Can we build a super-ensemble with thousands of those and see if we can reach 90% accuracy? \n",
    "* And finally, as always, play with the code and run different simulations: **more estimators, in Bagging more or less max_samples, etc.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
