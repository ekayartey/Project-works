{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Clusters\n",
    "\n",
    "This week we will use a sample of the world's cities, plotted in a map by latitude and longitude, to explore it and see if we can extract some clusters.\n",
    "\n",
    "First, we will download the data and display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will install this library to plot our data in a map\n",
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/bahar/WorldCityLocations/master/World_Cities_Location_table.csv'\n",
    "\n",
    "data_stream=requests.get(data_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'country', 'city', 'lat', 'lon', 'population']\n",
    "df=pd.read_csv(io.StringIO(data_stream.decode('utf-8')), sep=';', header=None)\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the map below faster to be plotted, we will only select 1000 random cities:\n",
    "sample = df.sample(1000, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_map = folium.Map(location=[0,0], zoom_start=1, \n",
    "tiles='cartodbpositron', width=700, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in sample.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        (row[1]['lat'], row[1]['lon']), \n",
    "        radius=1,\n",
    "        color='#0080bb', \n",
    "        fill_color='#0080bb'\n",
    "    ).add_to(world_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This is our raw data, plotted in a world map:')\n",
    "world_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First comparison\n",
    "\n",
    "Let's compare the performance of K-means, DBSCAN and OPTICS and display the clusters they come up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN, OPTICS\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, \\\n",
    "    calinski_harabasz_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display the clustering results.\n",
    "def plot_clustering_summary(clustering_data, result):\n",
    "    # We define this palette of colours to draw different clusters:\n",
    "    palette = [\n",
    "        '#ff6666', '#ffcc66', '#ccff66', '#66ff99', '#66e6ff', '#6666ff', '#e566ff', \n",
    "        '#4da6ff', '#e60073', '#2200cc', '#0088cc', '#19ffff', '#1eb300', '#805500',\n",
    "        '#7cb9e8', '#b0bf1a', '#5d8aa8', '#efdecd', '#3b7a57', '#967117', '#cce6ff',\n",
    "        '#ffff99', '#ff0000', '#00ff00', '#0000ff', '#c7d9d6', '#d99100', '#1a0800'\n",
    "              ]\n",
    "    \n",
    "    n_clusters = len(set(result))\n",
    "    \n",
    "    silhouette_avg = silhouette_score(clustering_data, result)\n",
    "    print(\"For n_clusters =\", n_clusters)\n",
    "    print(\"The average Silhouette score is :\", round(silhouette_avg, 4))\n",
    "    ch_score = calinski_harabasz_score(clustering_data, result)\n",
    "    print(\"The Calinski-Harabasz score is :\", round(ch_score, 4))\n",
    "    db_score = davies_bouldin_score(clustering_data, result)\n",
    "    print(\"The Davies-Bouldin score is :\", round(db_score, 4))\n",
    "    \n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(clustering_data, result)\n",
    "    y_lower = 10\n",
    "    fig, (ax1) = plt.subplots(figsize=(10, 7))\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, len(clustering_data) + (n_clusters + 1) * 10])\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[result == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        color = palette[i % len(palette)]\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    \n",
    "    result_map = folium.Map(location=[0,0], zoom_start=1, tiles='cartodbpositron', \n",
    "                            width=700, height=400)\n",
    "    for i in range(len(clustering_data)):\n",
    "        folium.CircleMarker(\n",
    "            (clustering_data.iloc[i]['lat'], clustering_data.iloc[i]['lon']), \n",
    "            radius=1,\n",
    "            color=palette[result[i] % len(palette)],\n",
    "            fill_color=palette[result[i] % len(palette)]\n",
    "        ).add_to(result_map)\n",
    "\n",
    "    plt.show()\n",
    "    return result_map         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will cluster data by their latitude and longitude (no city names or countries)\n",
    "clustering_data = sample[['lat', 'lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this value to modify the results from K-means. \n",
    "# For example... there are 6 continents... That's some a-priori knowledge\n",
    "NUM_CLUSTERS = 10\n",
    "\n",
    "# We will leave the other parameters not here as 'default'\n",
    "kmeans = MiniBatchKMeans(\n",
    "    n_clusters=NUM_CLUSTERS,\n",
    "    init='k-means++',\n",
    ")\n",
    "kmeans_clusters = kmeans.fit_predict(clustering_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_map = plot_clustering_summary(clustering_data, kmeans_clusters)\n",
    "res_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colours in this chart are the same as in the map.\n",
    "\n",
    "You can check which clusters are worse than others. In my execution, all of the clusters have a knife-style shape apart from the South American cluster.\n",
    "\n",
    "Let's check the **DBSCAN** algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(\n",
    "    eps=6,\n",
    "    min_samples=5\n",
    ")\n",
    "dbscan_clusters = dbscan.fit_predict(clustering_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_map = plot_clustering_summary(clustering_data, dbscan_clusters)\n",
    "res_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics = OPTICS(\n",
    "    min_samples=20\n",
    ")\n",
    "optics_clusters = optics.fit_predict(clustering_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_map = plot_clustering_summary(clustering_data, optics_clusters)\n",
    "res_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and learning exercises:\n",
    "\n",
    "* Why DBSCAN and OPTICS got worse performance metrics than k-means in this case?\n",
    "* Is there a way we could fix that?\n",
    "\n",
    "* Play with the parameters of the different algorithms to improve their performance.\n",
    "\n",
    "* Also, could you try to run the Spectral Clustering method? Before running it, do you think you will get better performance than k-means? Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
