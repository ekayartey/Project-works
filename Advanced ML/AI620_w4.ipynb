{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold Learning\n",
    "\n",
    "Today we are going to work with another example dataset based on images, called Olivetti Faces. This dataset contains 400 images of some people's faces. Each image is 64 x 64 pixels (4096 in total).\n",
    "\n",
    "That means that we have 4096 dimensions in the raw data!!\n",
    "\n",
    "### How can we visually analyse 400 images in one chart? \n",
    "Well that's precisely what Manifold Learning can help us with. But actually also Dimensionality Reduction techniques could help us right? Let's compare these two technique families and verify why Manifold Learning is more suitable for this task. In theory we know it should be better because images' similarities are nonlinear and because there are too many dimensions to convert into components.\n",
    "\n",
    "### In the 400 pictures, how many unique persons are represented?\n",
    "There are 400 pictures, but we know (because the data is labelled) that there are 39 different people. Therefore many pictures are of the same person's face (but slightly different). Could we also apply some clustering algorithm to group those faces and discover how many people are there? (without using the true labels). You could imagine that this is a security camera system and we want to automate this task of recognising unique persons.\n",
    "\n",
    "Or another example, your phone camera probably puts a square around people's faces ([like this](https://i1.wp.com/revoseek.com/wp-content/uploads/2012/03/Hitachis-Camera-Recognize-a-Person.jpg?resize=600%2C375)) before taking the picture: we could take the images inside those squares over a period of time and analyse how many different persons you are taking pictures of.\n",
    "\n",
    "This is what Facebook is doing since years ago when it suggests you to tag someone in a picture, and probably guessing correctly who the person in the photgraph is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap, MDS, LocallyLinearEmbedding, TSNE # There are more. Check them out\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If the next line of code doesn't work, run this:\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "'''\n",
    "\n",
    "faces = fetch_olivetti_faces()\n",
    "\n",
    "# faces is a dictionary with 3 keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`faces` is a dictionary with 4 keys:\n",
    "* images: The actual 400 black and white images of 64x64 pixels of people.\n",
    "* data: Same data as images, but 400 samples of 4096 columns (the pixels converted to input features)\n",
    "* target: An array of 400 integers, representing the class (each class represents a different person)\n",
    "* description: A description of the dataset. Shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faces.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400 images, 64 by 64 pixels.\n",
    "faces['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Insert any number between 0 and 399 to visualise one training data\n",
    "record. I put 0 for example. BUT TRY SOME OTHER:\n",
    "'''\n",
    "SAMPLE_RECORD_NUMBER = 0\n",
    "\n",
    "plt.gray() \n",
    "plt.matshow(faces.images[SAMPLE_RECORD_NUMBER]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some consecutive faces. You can change the parameter `grid_size` to show more or less faces, and the parameter `j` to show some other parts of the dataset (by default I am showing from the 100th data sample onwards). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 5\n",
    "\n",
    "fig, axes = plt.subplots(grid_size, grid_size, sharex=True, sharey=True,figsize=(15, 15))\n",
    "j=100\n",
    "\n",
    "for row in axes:\n",
    "    for i in range(grid_size):\n",
    "        row[i].matshow(faces.images[j])\n",
    "        j+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We humans can easily identify which picture corresponds to the same person. \n",
    "\n",
    "And in supervised learning we could do some feature selection and dimensionality reduction to create a classifier that could potentially perform well. Also, we could train an Artificial Neural Network which probably would work very well.\n",
    "\n",
    "But without having any class, in **purely unsupervised learning**, how can we separate the pictures of each person?\n",
    "\n",
    "To simplify this we will select the first 70 images. If anything we do with just 70 pictures works, we could then expand it to all of the data (with the same parameters) and check if the results are still good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 70\n",
    "\n",
    "df = pd.DataFrame(faces['data'][:N_IMAGES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we expected, 4096 input features...\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold Plots\n",
    "\n",
    "Let's use Manifold Learning to plot the images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['x', 'y']\n",
    "\n",
    "# I left some other parameters as default. You can check sklearn's docs\n",
    "isomap = Isomap(\n",
    "    n_neighbors=5, #num of neighbors for KNN \n",
    "    n_components=2, # 2D data as a result\n",
    "    n_jobs=-1\n",
    ")\n",
    "isomap_result = isomap.fit_transform(df)\n",
    "isomap_result = pd.DataFrame(isomap_result)\n",
    "isomap_result.columns = cols\n",
    "\n",
    "plt.scatter(isomap_result['x'], isomap_result['y'], color='b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Isomap: We can already see that some data points are quite similar and other quite different')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lle = LocallyLinearEmbedding(\n",
    "    n_neighbors=5, \n",
    "    n_components=2, \n",
    "    reg=0.001, \n",
    "    method='standard', # Could be {‘standard’, ‘hessian’, ‘modified’, ‘ltsa’} for all of the versions of LLE we saw\n",
    "    random_state=0, \n",
    "    n_jobs=-1\n",
    ")\n",
    "lle_result = lle.fit_transform(df)\n",
    "lle_result = pd.DataFrame(lle_result)\n",
    "lle_result.columns = cols\n",
    "plt.scatter(lle_result['x'], lle_result['y'], color='b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('LLE: Some small clusters of points are quite separated from the rest - what is happening?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-dimensional scaling algorithms:\n",
    "mds = MDS(\n",
    "    n_components=2, \n",
    "    metric=True, # To select metric or non-metric MDS\n",
    "    n_init=4, \n",
    "    max_iter=300, \n",
    "    verbose=0, \n",
    "    eps=0.001, \n",
    "    n_jobs=-1, \n",
    "    random_state=0, \n",
    "    dissimilarity='euclidean'\n",
    ")\n",
    "mds_result = mds.fit_transform(df)\n",
    "mds_result = pd.DataFrame(mds_result)\n",
    "mds_result.columns = cols\n",
    "plt.scatter(mds_result['x'], mds_result['y'], color='b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('MDS: And now all images look quite spread?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's try the big boy... As always: CHANGE PARAMETERS TO SEE HOW IT WORKS!!\n",
    "t_sne = TSNE(\n",
    "    n_components=2,\n",
    "    # I had to play with perplexity quite a bit: WHAT HAPPENS IF YOU INCREASE/DECREASE IT?\n",
    "    perplexity=5.6, \n",
    "    metric='euclidean', \n",
    "    # Can be random or pca. Try both!\n",
    "    init='pca', \n",
    "    verbose=0, \n",
    "    random_state=0, \n",
    "    # You can also put below 'exact', but you will have to approx double the perplexity factor\n",
    "    method='barnes_hut',\n",
    "    n_jobs=-1\n",
    ")\n",
    "t_sne_result = t_sne.fit_transform(df)\n",
    "t_sne_result = pd.DataFrame(t_sne_result)\n",
    "t_sne_result.columns = cols\n",
    "plt.scatter(t_sne_result['x'], t_sne_result['y'], color='b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('t-SNE: There are some clear clusters there now')\n",
    "plt.show()\n",
    "print('Are there around 7-10 clusters there or it is my imagination just?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Let's cluster that data that came out of t-SNE and see if we can more or less guess the number of groups/clusters (classes, **different people**) we have in there..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can see that one of the t-SNE clusters has 5 samples. Let's use 5 as the min_samples then:\n",
    "\n",
    "# I was playing with EPS and min_samples for a while UNTIL:\n",
    "#    1. I got as many samples as possible belonging to a cluster\n",
    "#    2. I got a reasonable number of clusters: no 1 single cluster, and no >10 clusters \n",
    "dbscan = DBSCAN(\n",
    "    eps=50,\n",
    "    min_samples=3,\n",
    "    \n",
    ")\n",
    "dbscan_clusters = dbscan.fit_predict(t_sne_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num. samples without cluster:', (dbscan_clusters == -1).sum())\n",
    "# DBSCAN thinks there are 4 different people:\n",
    "print('Clusters: ', set(dbscan_clusters))\n",
    "\n",
    "# The -1 cluster are those samples that are considered noise (don't belong to any cluster)\n",
    "# Now we will add these clusters to the different Manifold Learning results, and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [isomap_result, lle_result, mds_result, t_sne_result]\n",
    "algos = ['Isomap', 'LLE', 'MDS', 't-SNE']\n",
    "\n",
    "palette = [\n",
    "        '#aaaaaa', '#ff6666', '#66ccff', '#bbff88', '#3346ff', '#6666ff', '#e566ff', '#66ff99', \n",
    "        '#7cb9e8', '#b0bf1a', '#5d8aa8', '#efdecd', '#3b7a57', '#967117', '#cce6ff',\n",
    "        '#4da6ff', '#e60073', '#2200cc', '#0088cc', '#19ffff', '#1eb300', '#805500',\n",
    "]\n",
    "\n",
    "clusters = set(dbscan_clusters)\n",
    "\n",
    "for r in results:\n",
    "    r['dbscan'] = dbscan_clusters\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "res_index = 0\n",
    "\n",
    "for row in axes:\n",
    "    for i in range(2):\n",
    "        res = results[res_index]\n",
    "        for c in clusters:\n",
    "            cluster_data = res[res['dbscan']==c]\n",
    "            row[i].scatter(cluster_data['x'],cluster_data['y'], color=palette[c+1])\n",
    "        row[i].title.set_text(algos[res_index])\n",
    "        res_index+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only in t-SNE the images are separated more or less correctly. Although in all of the methods the images identified as \"being the same person\" by our `t-SNE + DBSCAN` approach are located nearby (even in LLE) \n",
    "The t-SNE clusters are all more or less coloured correctly. Let's assign those cluster values to the original data and **check if the images inside each cluster are of the same person**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters'] = dbscan_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between -1 and len(set(dbscan_clusters))\n",
    "CLUSTER_TO_DISPLAY = 2\n",
    "\n",
    "cluster_images = df[df['clusters'] == CLUSTER_TO_DISPLAY]\n",
    "\n",
    "print('This cluster has',len(cluster_images), 'photos')\n",
    "\n",
    "# IF THE CLUSTER HAS LESS THAN 9 IMAGES, THEY WILL BE REPEATED BELOW:\n",
    "grid_size = 3\n",
    "fig, axes = plt.subplots(grid_size, grid_size, sharex=True, sharey=True,figsize=(15, 15))\n",
    "\n",
    "img_count=0\n",
    "\n",
    "for row in axes:\n",
    "    for i in range(grid_size):\n",
    "        row[i].matshow(np.array(cluster_images.iloc[img_count % len(cluster_images)][:4096]).reshape(64, 64))\n",
    "        img_count+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kind of works...\n",
    "\n",
    "The best clusters for me where the young man of the very first picture we showed above in this notebook, and all of the gentlemen with glasses. \n",
    "\n",
    "t-SNE's low-dimensional visualisation kind of gave us the impression that there were between 5 and 10 clusters of data - which allowed us to tune DBSCAN to achieve an OK result to group the 70 pictures.\n",
    "\n",
    "What if we had used PCA for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_pca = PCA(n_components=2, svd_solver='auto')\n",
    "\n",
    "v_pca = vanilla_pca.fit_transform(df)\n",
    "print('Shape of the PCA-transformed data: ',v_pca.shape)\n",
    "print('Those are', v_pca.shape[1], 'components')\n",
    "print('Variance explained: ', round(100*sum(vanilla_pca.explained_variance_ratio_), 2), '% of the total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pca_result = pd.DataFrame(v_pca)\n",
    "v_pca_result.columns = cols\n",
    "plt.scatter(v_pca_result['x'], v_pca_result['y'], color='b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Classic PCA, reduced to 2 components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to happen the same as with MDS... the data is spread everywhere.\n",
    "\n",
    "##### Let's plot our OK-ish t-SNE-based clusters in that PCA 2D plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pca_result['dbscan'] = dbscan_clusters\n",
    "\n",
    "for c in clusters:\n",
    "    cluster_data = v_pca_result[v_pca_result['dbscan'] == c]\n",
    "    plt.scatter(cluster_data['x'], cluster_data['y'], color=palette[c+1])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Classic PCA, reduced to 2 components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is actually not too bad! Some of the clusters we discovered using t-SNE (non-linear Manifold Learning) are located nearby, and without overlaps, in PCA (linear Dimensionality Reduction technique).\n",
    "\n",
    "This means that there are _some linear relationships_ in our data that can be exploited by traditional Dimensionality Reduction techniques, even though PCA's 2 components are only able to explain around 40% of the original variance.\n",
    "\n",
    "Maybe we could have done our clustering directly on the original data? Or in a PCA (or other Dimensionality Reduction) with some higher number of components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to play with these two parameters a lot to obtain a result similar\n",
    "# to what we had after t-SNE!! \n",
    "# Without the knowledge from t-SNE and/or the target variable provided in \n",
    "# the dataset (faces['target']), this would have been a big guess to know how many clusters is\n",
    "# the correct result... or maybe not: what could we have done here?\n",
    "dbscan = DBSCAN(\n",
    "    eps=8.5,\n",
    "    min_samples=2,\n",
    "    \n",
    ")\n",
    "dbscan_clusters2 = dbscan.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num. samples without cluster:', (dbscan_clusters2 == -1).sum())\n",
    "print('Clusters: ', set(dbscan_clusters2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters2'] = dbscan_clusters2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between -1 and len(dbscan_clusters2)\n",
    "CLUSTER_TO_DISPLAY = 3\n",
    "\n",
    "cluster_images = df[df['clusters2'] == CLUSTER_TO_DISPLAY]\n",
    "\n",
    "print('Num. Images in Cluster:', len(cluster_images))\n",
    "\n",
    "# IF THE CLUSTER HAS LESS THAN 9 IMAGES, THEY WILL BE REPEATED BELOW:\n",
    "grid_size = 3\n",
    "fig, axes = plt.subplots(grid_size, grid_size, sharex=True, sharey=True,figsize=(15, 15))\n",
    "\n",
    "img_count=0\n",
    "\n",
    "for row in axes:\n",
    "    for i in range(grid_size):\n",
    "        row[i].matshow(np.array(cluster_images.iloc[img_count % len(cluster_images)][:4096]).reshape(64, 64))\n",
    "        img_count+=1\n",
    "\n",
    "plt.show()\n",
    "print('Seems like the clusters work - and contain the same person in all of them!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you checked the clusters, you'll notice that we are even able to differentiate the 2 gentlemen using the same pair of glasses.\n",
    "\n",
    "**Note:** The first time we clustered images, we used only 2 dimensions (those provided by t-SNE), and got fair-enough results. The second time, we used the 4096 original dimensions (all the pixels) to do the clustering!! In a very large dataset that would have taken ages!! So, while the second results are maybe slightly better for what I observed in the clusters, t-SNE helped us analyse our data to seek an ok-ish number of clusters that there should be, and then quickly apply any clustering algorithm there.\n",
    "\n",
    "Anyway... Congratulations! You have now the power of a face recognition software in your hands!\n",
    "\n",
    "# Learning Exercises:\n",
    "\n",
    "* What happens when you select more than 70 images? Does t-SNE still make sense?\n",
    "* Considering that we found out that _some_ linear relationships are present in the data, what else could we have done to discover how many classes we have?\n",
    "* How could we verify that our clusters of photos are correct? Can you apply those metrics and plots?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
